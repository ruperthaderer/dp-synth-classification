{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-08T19:39:00.943981Z",
     "start_time": "2025-12-08T19:39:00.923799Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "data = pd.read_csv('data\\\\br2000_mrf.csv')\n",
    "\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity/epsilon)\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  10  11  12  13\n",
       "0  0  0  2  1  3  0  0  1  0  0   6   1   5   0\n",
       "1  0  1  1  0  7  0  0  1  0  0   6   1   7   1\n",
       "2  1  1  2  1  6  0  0  1  0  3   4   1   8   1\n",
       "3  0  0  1  0  7  1  0  1  0  0   4   1   6   0\n",
       "4  0  0  6  0  1  1  0  0  0  1   8   1   2   0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:39:00.990055Z",
     "start_time": "2025-12-08T19:39:00.965883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#generate Phase 1\n",
    "\n",
    "def generate(df, numTuples=None, numClass=None, epsilon=1.0):\n",
    "    print(df.shape)\n",
    "    #optionale parameter abklären\n",
    "    if numTuples is None:\n",
    "        numTuples = df.shape[0]\n",
    "    if numClass is None:\n",
    "        numClass = df.shape[1] - 1\n",
    "\n",
    "    className = df.columns[numClass]\n",
    "    attributesName = [col for col in df.columns if col != className]\n",
    "\n",
    "    numHistograms = df.shape[1] - 1\n",
    "    epsilon_per_hist = epsilon/numHistograms\n",
    "\n",
    "    histograms = {} # Dict für jedes Marginal nach Attribut sortiert\n",
    "    for attributeName in attributesName:\n",
    "        counts = df[[attributeName, className]].value_counts() # Series mit MultiIndex, Ebene 0 = Attribut, Ebene 1 = Klasse\n",
    "        noisy_counts = laplace_mech(counts, 1, epsilon_per_hist)\n",
    "        noisy_counts.clip(lower=0.0, inplace=True) # Entfernen von negativen Werten\n",
    "        #noisy_counts = noisy_counts.round()\n",
    "        histograms[attributeName] = noisy_counts\n",
    "\n",
    "    print(histograms[\"1\"])\n",
    "\n",
    "generate(data)\n"
   ],
   "id": "104d19097a9ff58d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 14)\n",
      "1  13\n",
      "0  0     20336.530689\n",
      "1  0      6210.530689\n",
      "   1      5143.530689\n",
      "0  1      3360.530689\n",
      "2  1      1562.530689\n",
      "   0       777.530689\n",
      "3  1       247.530689\n",
      "   0        90.530689\n",
      "4  1        53.530689\n",
      "   0        12.530689\n",
      "5  1         0.000000\n",
      "6  1         0.000000\n",
      "5  0         0.000000\n",
      "6  0         0.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:39:01.155598Z",
     "start_time": "2025-12-08T19:39:01.042217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#generate Phase 2\n",
    "def generate(df, numTuples=None, numClass=None, epsilon=1.0):\n",
    "    print(df.shape)\n",
    "    #optionale parameter abklären\n",
    "    if numTuples is None:\n",
    "        numTuples = df.shape[0]\n",
    "    if numClass is None:\n",
    "        numClass = df.shape[1] - 1\n",
    "\n",
    "    className = df.columns[numClass]\n",
    "    attributesName = [col for col in df.columns if col != className]\n",
    "    numHistograms = df.shape[1] - 1\n",
    "    epsilon_per_hist = epsilon/numHistograms\n",
    "    histograms = {}\n",
    "    for attributeName in attributesName:\n",
    "        counts = df[[attributeName, className]].value_counts()\n",
    "        noisy_counts = laplace_mech(counts, 1, epsilon_per_hist)\n",
    "        noisy_counts.clip(lower=0.0, inplace=True)\n",
    "        #noisy_counts = noisy_counts.round()\n",
    "        histograms[attributeName] = noisy_counts\n",
    "# bis hier Phase 1\n",
    "\n",
    "    classTotals = {}\n",
    "    for attr_name, hist in histograms.items(): #key-value für das Histogramm-Dict sind Attributname und das dazugehörige Histogramm\n",
    "        for (attr_val, class_val), count in hist.items(): # key-value für die Histogramme selbst sind der multiIndex und die Counts\n",
    "            if class_val not in classTotals:\n",
    "                classTotals[class_val] = 0.0 # Eintrag erstellen, falls die Klasse noch nicht in classTotals angelegt wurde\n",
    "            classTotals[class_val] += count\n",
    "\n",
    "    total = sum(classTotals.values())\n",
    "    p = {c: classTotals[c] / total for c in classTotals} # Key: Klasse, Value: P(Klasse)\n",
    "\n",
    "    classTuples = {c: round(numTuples * p[c]) for c in classTotals} # Die Längen der Vektoren ist NumTuples * P(c=c_1)\n",
    "\n",
    "    class_vector = {c: [c] * classTuples[c] for c in classTuples } # Füllen Sie die Vektoren mit den zugehörigen c Werten.\n",
    "\n",
    "    cond_attr = {} # Dict für P(attr | class)\n",
    "\n",
    "    for attr_name, hist in histograms.items():   # pro Attribut\n",
    "        cond_attr[attr_name] = {}   # pro Attribut ein verschachteltes Dict\n",
    "        for c in classTotals:                    # pro Klasse\n",
    "            attr_counts = {}                     # neu für (attr, class)\n",
    "            for (attr_val, class_val), count in hist.items(): # pro Histogramm\n",
    "                if class_val == c:\n",
    "                    attr_counts[attr_val] = attr_counts.get(attr_val, 0) + count # wenn Eintrag existiert, wird der bisherige Count verwendet, wenn nicht, dann 0.\n",
    "\n",
    "            sum_c = sum(attr_counts.values())\n",
    "\n",
    "            if sum_c == 0:\n",
    "            # gleichverteilte Notlösung\n",
    "                if attr_counts: #Info über Klassen da, aber alle counts auf 0\n",
    "                    gleich = 1.0 / len(attr_counts)\n",
    "                    probs = {a: gleich for a in attr_counts}\n",
    "                else: # gar keine Werte – dann kannst du z.B. später skippen\n",
    "                    probs = {}\n",
    "            else:\n",
    "                probs = {a: attr_counts[a] / sum_c for a in attr_counts}\n",
    "            cond_attr[attr_name][c] = probs\n",
    "\n",
    "    attr_vectors = {} #MultiIndex, Attribut und Klasse, Value ist Vektor\n",
    "    for attr_name, class_dict in cond_attr.items():\n",
    "        attr_vectors[attr_name] = {}\n",
    "        for c,probs in class_dict.items():\n",
    "            n_c = classTuples[c]\n",
    "            target_count = {}\n",
    "\n",
    "            for attr_val, p_val in probs.items():\n",
    "                target_count[attr_val] = round(p_val * n_c)\n",
    "\n",
    "            attr_vec_c = [] # vektor pro klasse, mit Länge n_c, und values sind die attributwerte verteilt nach vorhin berechneten Ps\n",
    "            for attr_val, cnt in target_count.items():\n",
    "                attr_vec_c.extend([attr_val] * cnt)\n",
    "\n",
    "            # LÄNGE ANPASSEN!\n",
    "            n_c = classTuples[c]\n",
    "            current_len = len(attr_vec_c)\n",
    "            diff = n_c - current_len\n",
    "\n",
    "            if diff > 0:\n",
    "                vals = list(probs.keys())\n",
    "                extra = np.random.choice(vals, size=diff, p=list(probs.values()))\n",
    "                attr_vec_c.extend(extra)\n",
    "\n",
    "            elif diff < 0:\n",
    "                remove_indices = np.random.choice(len(attr_vec_c), size=-diff, replace=False)\n",
    "                for idx in sorted(remove_indices, reverse=True):\n",
    "                    attr_vec_c.pop(idx)\n",
    "\n",
    "            np.random.shuffle(attr_vec_c) # Mischen des Vektors in-place, evtl Datenleck (ohne shuffle Accuracy=1)\n",
    "\n",
    "            attr_vectors[attr_name][c] = attr_vec_c\n",
    "\n",
    "    blocks = {}\n",
    "    for c in classTuples:\n",
    "        n_c = classTuples[c]\n",
    "        block = {}\n",
    "\n",
    "        for attributeName in attributesName:\n",
    "            values = attr_vectors[attributeName][c] # Vektoren für jedes Attribut + aktuelle Klasse\n",
    "            #sanity check?\n",
    "            block[attributeName] = values\n",
    "        block[className] = class_vector[c]  # Vektor für die Klasse selbst\n",
    "        blocks[c] = block # Klassenvektor + einer pro Attribut für die aktuelle Klasse werden zu Blocks hinzugefügt.\n",
    "\n",
    "    df_blocks = {c: pd.DataFrame(block) for c, block in blocks.items()} # ein DataFrame pro Klasse\n",
    "    synthetic_df = pd.concat(df_blocks.values(), ignore_index=True) # Zusammenfügen der Klassen-DataFrames\n",
    "\n",
    "    #print(\"original:\", df.shape)\n",
    "    #print(\"synthetic:\", synthetic_df.shape)\n",
    "\n",
    "    synthetic_df = synthetic_df.sample(frac=1, random_state=42).reset_index(drop=True) #shuffling\n",
    "\n",
    "\n",
    "    #print(classTotals)\n",
    "    #print(p)\n",
    "    #print(classTuples)\n",
    "    #print(cond_attr)\n",
    "    #print(attr_vectors['13']['<=50K'])\n",
    "\n",
    "    return synthetic_df\n",
    "\n",
    "synthetic_data = generate(data)"
   ],
   "id": "982ce399b08d509a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 14)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:39:01.176272Z",
     "start_time": "2025-12-08T19:39:01.172241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#GPT Zelle\n",
    "def build_pipeline(clf=None):\n",
    "    \"\"\"\n",
    "    Baut eine sklearn-Pipeline:\n",
    "    - OneHotEncoding für alle Feature-Spalten (alle außer der letzten)\n",
    "    - Classifier (default: RandomForest, kann aber übergeben werden)\n",
    "    \"\"\"\n",
    "    if clf is None:\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    # Alle Spalten außer der letzten sind Features\n",
    "    # (funktioniert auch mit '0', '1', ..., '13' als Spaltennamen)\n",
    "    def make_preprocessor(df):\n",
    "        feature_cols = df.columns[:-1]\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), feature_cols)\n",
    "            ]\n",
    "        )\n",
    "        return preprocessor\n",
    "\n",
    "    # kleine Wrapperfunktion, damit wir df nicht global brauchen\n",
    "    def make_model(df):\n",
    "        preprocessor = make_preprocessor(df)\n",
    "        model = Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", clf)\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    return make_model\n",
    "\n",
    "\n",
    "def evaluate_df(df, clf=None, n_splits=10, test_size=0.2, base_random_state=0):\n",
    "    \"\"\"\n",
    "    - df: DataFrame mit letzter Spalte = Klasse\n",
    "    - clf: optionaler Classifier (sonst RandomForest)\n",
    "    - n_splits: wie viele verschiedene Train/Test-Splits (mit unterschiedlichen seeds)\n",
    "    - test_size: Anteil Testdaten\n",
    "    \"\"\"\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    make_model = build_pipeline(clf)\n",
    "\n",
    "    accuracies = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        rs = base_random_state + i\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=test_size,\n",
    "            random_state=rs,\n",
    "            stratify=y  # damit Klassenverteilung im Split erhalten bleibt\n",
    "        )\n",
    "\n",
    "        model = make_model(df)   # baut Pipeline mit passenden Spalten\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = (y_pred == y_test).mean()\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    return {\n",
    "        \"classes\": classes,\n",
    "        \"accuracies\": np.array(accuracies),\n",
    "        \"confusion_matrices\": confusion_matrices,\n",
    "    }\n"
   ],
   "id": "a2b3a07b1420e0d1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:40:24.609102Z",
     "start_time": "2025-12-08T19:39:01.198776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Synthetische Daten\n",
    "synthetic_data = generate(data)\n",
    "synth_results = evaluate_df(synthetic_data, n_splits=10)\n",
    "\n",
    "# Originaldaten (data) aus CSV\n",
    "orig_results = evaluate_df(data, n_splits=10)\n",
    "\n",
    "print(\"Originaldaten:\")\n",
    "print(\"  Accuracy mean:\", orig_results[\"accuracies\"].mean())\n",
    "print(\"  Accuracy std :\", orig_results[\"accuracies\"].std())\n",
    "print(\"  Confusion Matrix (Split 0):\")\n",
    "print(orig_results[\"confusion_matrices\"][0])\n",
    "print(\"  Klassenreihenfolge:\", orig_results[\"classes\"])\n",
    "\n",
    "print(\"\\nSynthetische Daten:\")\n",
    "print(\"  Accuracy mean:\", synth_results[\"accuracies\"].mean())\n",
    "print(\"  Accuracy std :\", synth_results[\"accuracies\"].std())\n",
    "print(\"  Confusion Matrix (Split 0):\")\n",
    "print(synth_results[\"confusion_matrices\"][0])\n",
    "print(\"  Klassenreihenfolge:\", synth_results[\"classes\"])\n",
    "\n",
    "synthetic_data.head()"
   ],
   "id": "f436ed03d7c446f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 14)\n",
      "Originaldaten:\n",
      "  Accuracy mean: 0.8010131578947368\n",
      "  Accuracy std : 0.003641695481967089\n",
      "  Confusion Matrix (Split 0):\n",
      "[[4964  541]\n",
      " [ 938 1157]]\n",
      "  Klassenreihenfolge: [0 1]\n",
      "\n",
      "Synthetische Daten:\n",
      "  Accuracy mean: 0.8159210526315789\n",
      "  Accuracy std : 0.0038559591611726997\n",
      "  Confusion Matrix (Split 0):\n",
      "[[5035  478]\n",
      " [ 927 1160]]\n",
      "  Klassenreihenfolge: [0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  10  11  12  13\n",
       "0  0  0  1  3  6  1  0  1  0  2   8   1   5   1\n",
       "1  0  1  4  2  3  0  0  0  0  0   4   1   4   0\n",
       "2  0  0  3  2  8  0  0  0  0  2   5   1   6   0\n",
       "3  1  1  4  1  3  1  1  1  0  0   4   1   5   0\n",
       "4  0  0  2  0  5  1  0  0  0  0   5   1   9   0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T19:40:41.976149Z",
     "start_time": "2025-12-08T19:40:24.631189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#version mit alternativem clf\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Synthetische Daten\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "synthetic_data = generate(data)   # deine Funktion\n",
    "synth_results = evaluate_df(synthetic_data, clf=clf, n_splits=10)\n",
    "\n",
    "# Originaldaten (data) aus CSV\n",
    "orig_results = evaluate_df(data, clf=clf, n_splits=10)\n",
    "\n",
    "print(\"Originaldaten:\")\n",
    "print(\"  Accuracy mean:\", orig_results[\"accuracies\"].mean())\n",
    "print(\"  Accuracy std :\", orig_results[\"accuracies\"].std())\n",
    "print(\"  Confusion Matrix (Split 0):\")\n",
    "print(orig_results[\"confusion_matrices\"][0])\n",
    "print(\"  Klassenreihenfolge:\", orig_results[\"classes\"])\n",
    "\n",
    "print(\"\\nSynthetische Daten:\")\n",
    "print(\"  Accuracy mean:\", synth_results[\"accuracies\"].mean())\n",
    "print(\"  Accuracy std :\", synth_results[\"accuracies\"].std())\n",
    "print(\"  Confusion Matrix (Split 0):\")\n",
    "print(synth_results[\"confusion_matrices\"][0])\n",
    "print(\"  Klassenreihenfolge:\", synth_results[\"classes\"])"
   ],
   "id": "7b03d8a215a8cd20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 14)\n",
      "Originaldaten:\n",
      "  Accuracy mean: 0.7616315789473684\n",
      "  Accuracy std : 0.004743124488867803\n",
      "  Confusion Matrix (Split 0):\n",
      "[[4716  789]\n",
      " [1015 1080]]\n",
      "  Klassenreihenfolge: [0 1]\n",
      "\n",
      "Synthetische Daten:\n",
      "  Accuracy mean: 0.7547368421052632\n",
      "  Accuracy std : 0.003486717971971137\n",
      "  Confusion Matrix (Split 0):\n",
      "[[4571  936]\n",
      " [ 887 1206]]\n",
      "  Klassenreihenfolge: [0 1]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
